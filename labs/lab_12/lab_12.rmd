---
title: "lab_12"
author: "Greg Morton"
date: "04/21/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## You will need

* A Census API key
* Our usual libraries, plus the geographic ones

## Load libraries and establish settings
```{r}
library(tidyverse)
library(tidycensus)
library(sf)
library(lubridate)

```

**Task** Create a codeblock and load appropriate packages and settings for this lab.

```{r}
# Turn off scientific notation
options(scipen=999)
```

## Questions

**Q1.** You are interested in tracking police incidents around the West Virginia University campus over time, with the goal of surfacing interesting incidents and patterns. In particular, you want to know whether the latest incident titles are relatively new/novel compared to previous reports and whether an incident has happened before in the past 30 days.

Using [CSV data](https://raw.githubusercontent.com/dwillis/wvu-projects/master/crime-log/crime_log.csv), making the column names more readable and ensuring each datetime is separated into a date column and an hour column and also create a day_of_week column and populate that using lubridate.

```{r}

wvu_crime <- read_csv("https://raw.githubusercontent.com/dwillis/wvu-projects/master/crime-log/crime_log.csv")


```

Then write code that will construct a paragraph about the data described above comparing the most recent data to the previous date and the most recent previous date for the same day of the week. To do that, you will need to produce:

1. A dataframe with the crime log data loaded and the datetime column converted to the proper datatype.
```{r}

wvu_crime$datetime <- wvu_crime$datetime %>% 
  mdy_hm() %>%
  as.Date()



wvu_crime  <- wvu_crime %>%
  rename(date = datetime)

```

2. Columns in your dataframe that contain the date, time and day of the week that each date represents (you may need to google how to do that).

```{r}

wvu_crime <- wvu_crime %>%
  mutate(weekday = wday(wvu_crime$date, label=TRUE))

```
3. Generate a dataframe of the most recent date's incidents.
```{r}
wvu_crime_today <- wvu_crime %>%
  filter(date == max(date)) 

```
4. Using the first title in that dataframe, find the number of incidents that occurred in the previous 30 days and write out a sentence using paste. The sentence should include the most recent date, the title of the incident and the number of times that kind of incident has occurred in the previous 30 days.
```{r}
today <- wvu_crime %>%
  filter(date == max(date))

today_crime <- wvu_crime %>%
  filter(date == max(date)) %>% 
  select(title) %>% 
  head(1) %>% 
  unlist %>%
  as.vector() 

today_crime_lower <- today_crime  %>% 
  str_to_lower()

today_crime_title <- today_crime  %>% 
  str_to_title()


today_count <- today %>%
  count() %>%
  unlist() %>%
  as.vector() 






last_month <- wvu_crime %>%
  filter(date >= max(date) - 30) 

last_month_today <- wvu_crime %>%
  filter(date == max(date) - 30) %>% 
  count() %>%
  unlist() %>%
  as.vector() 



last_month_count <- last_month %>%
  count() %>%
  unlist() %>%
  as.vector() 

last_month_count <- last_month %>%
  count() %>%
  unlist() %>%
  as.vector() 

last_month_crime_count <- last_month %>%
  filter(title == today_crime) %>%
  count() %>%
  unlist() %>%
  as.vector() 

test <- case_when(
  today_count > last_month_today ~ print("an increase"),
  today_count < last_month_today ~ print("a decrease"),
  today_count == last_month_today ~ print("incidents remained steady"),
  TRUE ~ print("error")
)

test2 <- case_when(
  today_count > last_month_today ~ print("of"),
  today_count < last_month_today ~ print("of"),
  today_count == last_month_today ~ print("at"),
  TRUE ~ print("error")
)

test3 <- today$date %>%
  head(1)

test3 <- format.Date(test3, format = "%B %d, %Y")

pct_change <- paste0(((today_count - last_month_today) / last_month_today) * 100, "%")









```

Put your sentence in the answer below, along with one other question you could ask of this data.

**A1.**: **I added month over month percentage change, but I'd also be interested into knowing percentage breakdown of reported incidents month to month**

```{r}
wvu_crime_statement <- paste("On", paste0(test3, ","),today_count,"incidents were reported at WVU including",paste0("'",today_crime_lower,"'", "."),"This represents",test, test2, pct_change,"from", last_month_today,"reported incidents", "30 days before.", paste0("'",today_crime_title,"'"), "has been reported", last_month_crime_count, "times in the last 30 days.")

wvu_crime_statement
```


**Q2.** Maryland produces a [CSV file](https://raw.githubusercontent.com/state-of-maryland/VaccineCSVs/master/Vax_ZIP_CODE_FirstSecondSingle_Totals_Raw.csv) showing the total number of vaccinations by zip code and -- interestingly -- it includes non-Maryland zip codes (as well as some zip codes that seem to be bad data). write a script that reads the CSV file, making the columns more readable and adding today's date. Then output the top 25 Maryland zip codes and top 25 non-Maryland zip codes based on number of people fully vaccinated, and write both dataframes out to CSV files, using the following name formats:

```{r}

zip_vaxx <- read_csv("https://raw.githubusercontent.com/state-of-maryland/VaccineCSVs/master/Vax_ZIP_CODE_FirstSecondSingle_Totals_Raw.csv")

full_zips <- zip_vaxx %>%
  filter(nchar(ZIP_CODE) == 5) 


full_zips$ZIP_CODE <- full_zips$ZIP_CODE %>% as.character()

full_zips <- full_zips %>%
  rename(zip = ZIP_CODE) 



md_rough <- read_csv("data/md_zips_rough.csv")

md_zips_test <- get_acs(geography = "zcta", 
        variables = c(population = "B01001_001"), 
        state = "MD") %>%
    rename(population = estimate,
         zip = GEOID) %>%
  select(zip)

md_rough$zip <- md_rough$zip %>% as.character

md_vaxx <- md_zips_testh %>%
  left_join(full_zips, by = "zip")

md_all_zips <- md_rough %>%
  select(zip)


non_md_zips <- full_zips %>% 
  anti_join(md_all_zips,by = "zip")

date <- now() %>%
  as.Date()

md_save <- paste0("data/maryland_zips",date,".csv")

non_md_save <- paste0("data/non_maryland_zips",date,".csv")

non_md_vaxx <- non_md_zips %>% 
  filter(!is.na(FullyVaccinated))

md_vaxx %>% 
  filter(!is.na(FullyVaccinated))

md_most_vaxxed <- md_vaxx %>%
  arrange(desc(FullyVaccinated)) %>%
  head(25)

md_least_vaxxed <- md_vaxx %>% 
  arrange(FullyVaccinated) %>%
  head(25)

non_md_most_vaxxed <- non_md_vaxx %>% 
  arrange(FullyVaccinated) %>%
  head(25)

non_md_least_vaxxed <- non_md_vaxx %>% 
  arrange(FullyVaccinated) %>%
  head(25)



md_most_vaxxed
```


Maryland zips: maryland_zips_yyyymmdd.csv
Non-Maryland zips: non_maryland_zips_yyyymmdd.csv

Where yymmdd is from today's date. You MUST do this programmatically so that it can run every day without being updated. Be sure to add those two files to your GitHub repository.

To do that, you will need to:

1. Get rid of rows that do not have data for fully vaccinated people
2. Remove any rows where the zip code is less than five digits (there are several ways you could do this).
3. Figure out the "lowest" and "highest" Maryland zip codes.

Google the top 2-3 zip codes from both Maryland and non-Maryland results and describe them in your answer.

**A2.**: **7 of the top 10 are all Montgomery County, makes since because it is near DC and a lot of people live and work there**

```{r}

write_csv(md_most_vaxxed, md_save)

write_csv(non_md_most_vaxxed, non_md_save)

```

**Q3.** Maryland has had one of the more successful vaccination rates, but you want to understand where a significant portion of the population remains less than fully vaccinated. Make a dataframe of all Maryland zip codes from the vaccination data you used in Q2 and join it to Maryland zip code population data from the Census API. Calculate the percentage of fully vaccinated for each zip code and then make a map showing the zip codes with less than 50 percent fully vaccinated. Put a blank map with the outline of Maryland counties (which you can get from Tigris) behind it for context. Add a label to the map describing what the data is and include the date from the vaccination data (programmatically, so you can run it every day).

You WILL need to ensure that the columns you use to join the two dataframes are the same datatype and remember that join order matters.

Describe the output of the map below, and say what you think the most interesting areas are.

**A3.**: **This is actually very, very cool.  There's a pattern of zip codes at Maryland's margins having some of the lowest rates of full vaccination in the state.  This suggests that people may be getting 1 or both doses either at more central areas in the state or out of state (or a mix of both)**

```{r}

md_zip_pop <- get_acs(geography = "zcta", 
        variables = c(population = "B01001_001"), 
        state = "MD", 
        geometry = T) 


  

md_zip_pop <- md_zip_pop %>% 
  rename(population = estimate,
         zip = GEOID) %>%
  select(zip, population, geometry)


md_vaxx_for_map <- md_vaxx %>% 
  left_join(md_zip_pop) %>%
  select(zip, population, FullyVaccinated, geometry) %>%
  mutate(pct_vaxxed = (FullyVaccinated / population) * 100) 


md_vaxx_for_map %>% 
  filter(pct_vaxxed <= 50)

md_vaxx_for_map <- md_vaxx_for_map %>%
  mutate(under_50 = case_when(
    pct_vaxxed <= 50 ~ pct_vaxxed,
    pct_vaxxed > 50 ~ NA_real_ ))




ggplot() +
  geom_sf(data=md_vaxx_for_map, aes(fill=under_50, geometry = geometry)) +
  theme_minimal() +
  scale_fill_viridis_b(option="magma") 




```
